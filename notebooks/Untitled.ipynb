{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a2a8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9afa1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"proceessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e4c5cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16415</th>\n",
       "      <td>chang thay anh online gi ca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10226</th>\n",
       "      <td>that sounds cool and youre paying  even better</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23274</th>\n",
       "      <td>oh those messages probably not</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>where are you going paris</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>ooh which two books did you buy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "16415                      chang thay anh online gi ca          0\n",
       "10226   that sounds cool and youre paying  even better          1\n",
       "23274                   oh those messages probably not          0\n",
       "1969                         where are you going paris          0\n",
       "5033                   ooh which two books did you buy          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cf54f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71ae76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled index 24112 with text: hello\n"
     ]
    }
   ],
   "source": [
    "def fill_null_text(df, fill_text=\"hello\"):\n",
    "    # Find the first index where 'text' is null\n",
    "    null_index = df[df['text'].isnull()].index[0]  # Get the first null index\n",
    "    \n",
    "    # Replace the null value at the found index with the provided text\n",
    "    df.at[null_index, 'text'] = fill_text\n",
    "    \n",
    "    # Verify the change by printing the updated value\n",
    "    print(f\"Filled index {null_index} with text: {df['text'][null_index]}\")\n",
    "    \n",
    "\n",
    "fill_null_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "262e4d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0be21b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None,use_idf=True,norm='l2',smooth_idf=True)\n",
    "y=df.sentiment.values\n",
    "x=tfidf.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8bc040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.5,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3ffb858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:  2.0min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf=LogisticRegressionCV(cv=6,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=500).fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f5c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7382743716984153\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72a31a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf,open('clf_loggi_reg.pkl','wb'))\n",
    "pickle.dump(tfidf,open('tfidf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "069c5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    # Check if text is a string\n",
    "    if isinstance(text, str):\n",
    "        # Remove HTML tags\n",
    "        clean = re.compile('<.*?>')\n",
    "        text = re.sub(clean, '', text)  # Correctly assign the cleaned text\n",
    "        \n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove non-alphabetic characters (keep spaces)\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        return cleaned_text  # Return the final cleaned text\n",
    "    else:\n",
    "        return text  # Return the original text if it's not a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cdae59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(comment):\n",
    "    preprocessed_comment = preprocessing(comment)\n",
    "    comment_list = [preprocessed_comment]  # Wrap the preprocessed comment in a list\n",
    "    comment_vector = tfidf.transform(comment_list)\n",
    "    prediction = clf.predict(comment_vector)[0]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "prediction = prediction('i hate  you ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "826ceffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative comment\n"
     ]
    }
   ],
   "source": [
    "if prediction == 0:\n",
    "    print(\"neutral comment\")\n",
    "elif prediction == 1:\n",
    "    print(\"positive comment\")\n",
    "elif prediction == 2:\n",
    "    print(\"negative comment\")\n",
    "else:\n",
    "    print(\"suicide comment\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb9bd537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.503281575156075,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.54      0.46      0.50      5628\\n           1       0.83      0.34      0.48      4315\\n           2       0.83      0.11      0.20      3860\\n           3       0.42      1.00      0.59      4938\\n\\n    accuracy                           0.50     18741\\n   macro avg       0.66      0.48      0.44     18741\\nweighted avg       0.64      0.50      0.46     18741\\n',\n",
       " array([[2592,  235,   71, 2730],\n",
       "        [1205, 1473,   18, 1619],\n",
       "        [ 991,   60,  439, 2370],\n",
       "        [   8,    1,    1, 4928]], dtype=int64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Redefine the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the Naive Bayes model on the cleaned data\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model with predictions\n",
    "y_pred_cleaned = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, classification report, and confusion matrix\n",
    "accuracy_cleaned = accuracy_score(y_test, y_pred_cleaned)\n",
    "classification_rep_cleaned = classification_report(y_test, y_pred_cleaned)\n",
    "conf_matrix_cleaned = confusion_matrix(y_test, y_pred_cleaned)\n",
    "\n",
    "accuracy_cleaned, classification_rep_cleaned, conf_matrix_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44d8321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.503281575156075\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b75ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7412091137079131\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.80      0.68      5628\n",
      "           1       0.79      0.65      0.72      4315\n",
      "           2       0.71      0.50      0.59      3860\n",
      "           3       0.98      0.94      0.96      4938\n",
      "\n",
      "    accuracy                           0.74     18741\n",
      "   macro avg       0.77      0.72      0.73     18741\n",
      "weighted avg       0.76      0.74      0.74     18741\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4511  523  547   47]\n",
      " [1325 2816  155   19]\n",
      " [1709  164 1943   44]\n",
      " [ 171   44  102 4621]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 4: Model Training with XGBoost\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3089325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb_model,open('xgb_model.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fd604b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 - 200s - loss: 0.7420 - accuracy: 0.6683 - val_loss: 0.5911 - val_accuracy: 0.7591 - 200s/epoch - 333ms/step\n",
      "Epoch 2/4\n",
      "600/600 - 215s - loss: 0.5308 - accuracy: 0.7879 - val_loss: 0.5494 - val_accuracy: 0.7750 - 215s/epoch - 359ms/step\n",
      "Epoch 3/4\n",
      "600/600 - 204s - loss: 0.4698 - accuracy: 0.8141 - val_loss: 0.5528 - val_accuracy: 0.7794 - 204s/epoch - 339ms/step\n",
      "Epoch 4/4\n",
      "600/600 - 208s - loss: 0.4365 - accuracy: 0.8298 - val_loss: 0.5821 - val_accuracy: 0.7698 - 208s/epoch - 347ms/step\n",
      "235/235 [==============================] - 5s 19ms/step\n",
      "Accuracy: 0.7697745764972656\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66      2234\n",
      "           1       0.75      0.78      0.77      1720\n",
      "           2       0.65      0.71      0.68      1538\n",
      "           3       0.95      0.97      0.96      2005\n",
      "\n",
      "    accuracy                           0.77      7497\n",
      "   macro avg       0.76      0.77      0.77      7497\n",
      "weighted avg       0.77      0.77      0.77      7497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "data_cleaned = df.dropna(subset=['text'])\n",
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Step 2: Tokenization and Padding\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X_tokenized = tokenizer.texts_to_sequences(X.values)\n",
    "X_padded = pad_sequences(X_tokenized, maxlen=max_len)\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Build LSTM Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4, activation='softmax'))   # Assuming 3 sentiment classes\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Training the model\n",
    "batch_size = 50\n",
    "epochs = 4\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ce222a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRUST\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Step 1: Save the trained LSTM model\n",
    "model.save('lstm_sentiment_model.h5')  # This saves the Keras model in HDF5 format\n",
    "\n",
    "# Step 2: Save the tokenizer using pickle\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)\n",
    "\n",
    "print(\"Model and tokenizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7b8150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step\n",
      "negative comment\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Step 1: Load the saved LSTM model and tokenizer\n",
    "model = load_model('lstm_sentiment_model.h5')\n",
    "\n",
    "with open('tokenizer.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "# Step 2: Preprocess the input comment (assuming a simple preprocessing function)\n",
    "\n",
    "\n",
    "# Step 3: Function for predicting sentiment using the LSTM model\n",
    "def prediction(comment):\n",
    "    # Preprocess the input comment\n",
    "    preprocessed_comment = preprocessing(comment)\n",
    "    \n",
    "    # Tokenize and pad the comment\n",
    "    comment_sequence = tokenizer.texts_to_sequences([preprocessed_comment])\n",
    "    comment_padded = pad_sequences(comment_sequence, maxlen=100)  # Use the same maxlen used during training\n",
    "    \n",
    "    # Make a prediction using the LSTM model\n",
    "    prediction = np.argmax(model.predict(comment_padded), axis=1)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Step 4: Predict sentiment and print results\n",
    "input_comment = 'I hated this movie. Hated hated hated hated hated this movie. Hated it.\" He went on to call it \"a bad film - one of the worst movies ever made.'\n",
    "pred = prediction(input_comment)\n",
    "\n",
    "if pred == 0:\n",
    "    print(\"neutral comment\")\n",
    "elif pred == 1:\n",
    "    print(\"positive comment\")\n",
    "elif pred == 2:\n",
    "    print(\"negative comment\")\n",
    "else:\n",
    "    print(\"suicide comment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a0434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5ae0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
